{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a76afd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.4.1\n",
      "Keras version: 2.4.0\n",
      "Eager mode enabled: True\n",
      "Num GPUs Available:  0\n",
      "Num CPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import sys; sys.path.insert(0, '..') # add parent folder path where lib folder is\n",
    "import lib.metrics\n",
    "import lib.load_data\n",
    "import lib.evaluate\n",
    "\n",
    "import archs.unet\n",
    "import archs.multiresunet\n",
    "import archs.attentionunet\n",
    "import archs.nestedunet\n",
    "import archs.iterlunet\n",
    "\n",
    "from archs.unet import UNet\n",
    "from archs.multiresunet import MultiResUnet\n",
    "from archs.nestedunet import NestedUNet\n",
    "from archs.attentionunet import AttUNet\n",
    "from archs.iterlunet import IterLUNet\n",
    "\n",
    "from lib.evaluate import testModel\n",
    "from lib.load_data import get_data\n",
    "import cv2\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, model_from_json\n",
    "\n",
    "print('TensorFlow version: {version}'.format(version=tf.__version__))\n",
    "print('Keras version: {version}'.format(version=tf.keras.__version__))\n",
    "print('Eager mode enabled: {mode}'.format(mode=tf.executing_eagerly()))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Num CPUs Available: \", len(tf.config.list_physical_devices('CPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed3dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(test_ids, image_path, mask_path, unet, multiresunet, attnunet, nestedunet, proposed):\n",
    "    ids = test_ids\n",
    "    # empty list to store results\n",
    "    image_names, mask1, mask2, mask3, mask4, mask5,image_id, mask_id, has_mask = [], [], [], [], [], [],[], [], []\n",
    "    \n",
    "    image_path = os.path.abspath(image_path)\n",
    "    mask_path = os.path.abspath(mask_path)\n",
    "    #itetrating through each image in test data\n",
    "    for n, i in tqdm(enumerate(ids), total=len(ids)):\n",
    "        filename = i\n",
    "        image_names.append(filename)\n",
    "        #i = i.split('/')[-1]\n",
    "        i = image_path + '/' + i\n",
    "\n",
    "        #Creating a empty array of shape 1,256,256,1\n",
    "        X = np.empty((1,256,256,3))\n",
    "        # read the image\n",
    "        img = io.imread(i)\n",
    "        #resizing the image and coverting them to array of type float64\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        img = np.array(img)\n",
    "        \n",
    "        # standardising the image\n",
    "        #img -= img.mean()\n",
    "        #img /= img.std()\n",
    "        img = img / 255\n",
    "        #converting the shape of image from 256,256,3 to 1,256,256,3\n",
    "        X[0,] = img\n",
    "        \n",
    "        #make prediction of mask\n",
    "        predict1 = unet.predict(X)\n",
    "        predict2 = multiresunet.predict(X)\n",
    "        predict3 = attnunet.predict(X)\n",
    "        predict4 = nestedunet.predict(X)\n",
    "        predict5 = proposed.predict(X)\n",
    "        \n",
    "        image_id.append(image_path + '/' + filename)\n",
    "        mask_id.append(mask_path + '/' + format(filename.split('.')[0]+'.png'))\n",
    "        has_mask.append(1)\n",
    "    \n",
    "        mask1.append(predict1)\n",
    "        mask2.append(predict2)\n",
    "        mask3.append(predict3)\n",
    "        mask4.append(predict4)\n",
    "        mask5.append(predict5)\n",
    "            \n",
    "            \n",
    "    return pd.DataFrame({'file_name':image_names,'image_path': image_id, 'mask_path': mask_id,  'UNet_mask': mask1, 'MultiresUNet_mask': mask2, 'AttentionUNet_mask': mask3,\n",
    "                         'NestedUNet_mask': mask4, 'IterLUNet_mask':mask5, 'has_mask': has_mask})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa8540a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(y_true_in, y_pred_in):\n",
    "    smooth = 1e-15\n",
    "    intersection = y_true_in.ravel() * y_pred_in.ravel()\n",
    "    union = y_true_in.ravel() + y_pred_in.ravel() - intersection\n",
    "\n",
    "    iou = ((np.sum(intersection) + smooth)/(np.sum(union) + smooth))\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39d748ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing prediction\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "def show_visualization(df_pred,experiment_name):\n",
    "    count = 0\n",
    "    fig, axs = plt.subplots(8,7, figsize=(48, 62))\n",
    "    \n",
    "    \n",
    "    #df_pred = df_pred.sample(frac = 0.8)\n",
    "    #df_pred = df_pred.sample(n=len(df_pred), random_state=2022)\n",
    "    for i in range(len(df_pred)):\n",
    "        if df_pred.has_mask[i]==1 and count<8:\n",
    "            \n",
    "            #read levee crack image\n",
    "            img = cv2.imread(df_pred.image_path[i], cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (256,256))\n",
    "            #img = np.array(img, dtype = np.float64)\n",
    "            axs[count][0].imshow(img)\n",
    "            axs[count][0].set_axis_off() \n",
    "            axs[count][0].set_title('Original Image ' + str(count+1), fontsize=56)\n",
    "    \n",
    "    \n",
    "            \n",
    "            #read original mask and overlay original mask with levee crack image    \n",
    "            mask = cv2.imread(df_pred.mask_path[i], cv2.IMREAD_GRAYSCALE)\n",
    "            mask = cv2.resize(mask, (256, 256))\n",
    "            \n",
    "            img[mask==255] = (255,0,0)\n",
    "            axs[count][1].imshow(img)\n",
    "            axs[count][1].set_axis_off()\n",
    "            axs[count][1].set_title('Ground Truth '+ str(count+1), fontsize=56)\n",
    "            mask = np.array(mask, dtype = np.float64)\n",
    "            mask = mask / 255\n",
    "            \n",
    "        \n",
    "            \n",
    "            #pred_unet = np.array(df_pred.UNet_mask[i]).squeeze().round()\n",
    "            pred_unet = np.array(df_pred.UNet_mask[i])\n",
    "            iou_unet = iou_metric(mask, pred_unet )\n",
    "            pred_unet = np.round(pred_unet,0).squeeze()\n",
    "            img1 = cv2.imread(df_pred.image_path[i], cv2.IMREAD_COLOR)\n",
    "            img1 = cv2.resize(img1, (256,256))\n",
    "            img1 = img1.squeeze()\n",
    "            img1[pred_unet==1] = (0,0,0)\n",
    "            axs[count][2].imshow(img1)\n",
    "            axs[count][2].set_axis_off()\n",
    "            axs[count][2].set_title('[IoU M1=' + str(round(iou_unet,2)) + ']', fontsize=56)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #pred_multiresunet = np.array(df_pred.MultiresUNet_mask[i]).squeeze().round()\n",
    "            pred_multiresunet = np.array(df_pred.MultiresUNet_mask[i])\n",
    "            iou_multiresunet = iou_metric(mask, pred_multiresunet )\n",
    "            pred_multiresunet = np.round(pred_multiresunet,0).squeeze()\n",
    "            img2 = cv2.imread(df_pred.image_path[i], cv2.IMREAD_COLOR)\n",
    "            img2 = cv2.resize(img2, (256,256))\n",
    "            img2 = img2.squeeze() / 255\n",
    "            img2[pred_multiresunet==1] = (0,0,0)\n",
    "            axs[count][3].imshow((img2 * 255).astype(np.uint8))\n",
    "            axs[count][3].set_axis_off()\n",
    "            axs[count][3].set_title('[IoU M2=' + str(round(iou_multiresunet, 2)) + ']', fontsize=56)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            #pred_attentionunet = np.array(df_pred.AttentionUNet_mask[i]).squeeze().round()\n",
    "            pred_attentionunet = np.array(df_pred.AttentionUNet_mask[i])\n",
    "            iou_attentionunet = iou_metric(mask, pred_attentionunet )\n",
    "            pred_attentionunet = np.round(pred_attentionunet,0).squeeze()\n",
    "            img3 = cv2.imread(df_pred.image_path[i], cv2.IMREAD_COLOR)\n",
    "            img3 = cv2.resize(img3, (256,256))\n",
    "            img3 = img3.squeeze() / 255\n",
    "            img3[pred_attentionunet==1] = (0,0,0)\n",
    "            axs[count][4].imshow((img3 * 255).astype(np.uint8))\n",
    "            axs[count][4].set_axis_off() \n",
    "            axs[count][4].set_title('[IoU M3=' + str(round(iou_attentionunet, 2)) + ']', fontsize=56)\n",
    "            \n",
    "            \n",
    "            #pred_nestedunet = np.array(df_pred.NestedUNet_mask[i]).squeeze().round()\n",
    "            pred_nestedunet = np.array(df_pred.NestedUNet_mask[i])\n",
    "            iou_nestedunet = iou_metric(mask, pred_nestedunet )\n",
    "            pred_nestedunet = np.round(pred_nestedunet,0).squeeze()\n",
    "            img4 = cv2.imread(df_pred.image_path[i], cv2.IMREAD_COLOR)\n",
    "            img4 = cv2.resize(img4, (256,256))\n",
    "            img4 = img4.squeeze()\n",
    "            img4[pred_nestedunet==1] = (0,0,0)\n",
    "            axs[count][5].imshow(img4)\n",
    "            axs[count][5].set_axis_off() \n",
    "            axs[count][5].set_title('[IoU M4=' + str(round(iou_nestedunet, 2)) + ']', fontsize=56)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #pred_inception = np.array(df_pred.IterLUNet[i]).squeeze().round()\n",
    "            pred_inception = np.array(df_pred.IterLUNet_mask[i])\n",
    "            iou_inception = iou_metric(mask, pred_inception )\n",
    "            pred_inception = np.round(pred_inception,0).squeeze()\n",
    "            img5 = cv2.imread(df_pred.image_path[i], cv2.IMREAD_COLOR)\n",
    "            img5 = cv2.resize(img5, (256,256))\n",
    "            img5 = img5.squeeze() \n",
    "            img5[pred_inception==1] = (0,0,255)\n",
    "            axs[count][6].imshow(img5)\n",
    "            axs[count][6].set_axis_off() \n",
    "            axs[count][6].set_title('[IoU M5=' + str(round(iou_inception, 2)) + ']', fontsize= 56)\n",
    "            \n",
    "            \n",
    "            fig.subplots_adjust(top=0.96)\n",
    "            fig.tight_layout()\n",
    "            #plt.suptitle('Results of all models on hold-out levee crack test images', fontweight='regular', fontsize=16)\n",
    "            plt.savefig(str(experiment_name)  + '.png', format='png', facecolor=\"w\", transparent=False)\n",
    "        \n",
    "            count +=1\n",
    "        if (count==10):\n",
    "            break\n",
    "    fig.tight_layout() \n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed236cb-eb60-494d-9c13-6807c8445a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 256, 256, 3)\n",
      "Getting and resizing images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:01<00:00, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "(26, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#ata_path = \"/mnt/batch/tasks/shared/LS_root/mounts/clusters/exptl/code/Users/mpanta2/datasets/LeveeCrackDataset/augmentedLeveeCrack\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "path_test = \"/home/mpanta1/workspace/deeplearning/image_segmentation/unet_architecture/IEEEAccess_code_test/IterLUNet/dataset/experiment_2/test\"\n",
    "test_images = sorted(next(os.walk(path_test + \"/images\"))[2])\n",
    "\n",
    "X_test, y_test = get_data(test_images, path_test, img_height, img_width, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d592172-5c34-41c7-8f58-06cf3413a0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(237, 256, 256, 3)\n",
      "Getting and resizing images ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 237/237 [00:07<00:00, 33.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "(237, 256, 256, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path_test= \"../dataset/experiment_2/deepcrack_test_data/\"\n",
    "test_images_deepcrack = (next(os.walk(path_test + \"/images\"))[2])\n",
    "\n",
    "deepcrack_path_test = \"../dataset/experiment_2/deepcrack_test_data\"\n",
    "test_images = sorted(next(os.walk(deepcrack_path_test + \"/images\"))[2])\n",
    "\n",
    "X_test_DC, y_test_DC = get_data(test_images, deepcrack_path_test, img_height, img_width, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a15e20b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 21:40:43.315520: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48 µs, sys: 51 µs, total: 99 µs\n",
      "Wall time: 87.5 µs\n",
      "IterLUNet model loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 21:40:47.198028: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-09-13 21:40:47.198779: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 52s 7s/step\n",
      "0.72641695 0.39532253 0.5120065\n",
      "Test Jacard Index : 0.35493225824922614\n",
      "Test Dice Coefficient : 0.458476310104759\n",
      "Test iou_all :0.36373677387961173\n",
      "60/60 [==============================] - 439s 7s/step\n",
      "0.74644953 0.73572195 0.7410469\n",
      "Test Jacard Index : 0.580033763600379\n",
      "Test Dice Coefficient : 0.7245992568816298\n",
      "Test iou_all :0.5850898225966435\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "%time\n",
    "print('IterLUNet model loaded')\n",
    "inception_64_model = IterLUNet(input_filters=64, height=img_height, width=img_width, n_channels=3)\n",
    "inception_64_model.load_weights(\"../models/experiment_2/iterlunet.h5\")\n",
    "results_levee = testModel(inception_64_model, X_test, y_test, 4, 'iterlunet_levee')\n",
    "results_deepcrack = testModel(inception_64_model, X_test_DC, y_test_DC, 4, 'iterlunet_deepcrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f063734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 µs, sys: 0 ns, total: 32 µs\n",
      "Wall time: 68.4 µs\n",
      "UNet model loaded\n",
      "7/7 [==============================] - 4s 507ms/step\n",
      "0.64436466 0.37728974 0.47591865\n",
      "Test Jacard Index : 0.28156021390619385\n",
      "Test Dice Coefficient : 0.41422363555919184\n",
      "Test iou_all :0.2846818394142164\n",
      "60/60 [==============================] - 31s 518ms/step\n",
      "0.813713 0.51647717 0.6318859\n",
      "Test Jacard Index : 0.436969927360464\n",
      "Test Dice Coefficient : 0.5843404320748554\n",
      "Test iou_all :0.442445808655636\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "%time\n",
    "print('UNet model loaded')\n",
    "UNet_model = UNet(input_filters=32, height=img_height, width=img_width, n_channels=3)\n",
    "UNet_model.load_weights(\"../models/experiment_2/unet.hdf5\")\n",
    "results_levee = testModel(UNet_model, X_test, y_test, 4, 'unet_levee')\n",
    "results_deepcrack = testModel(UNet_model, X_test_DC, y_test_DC, 4, 'unet_deepcrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f235bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 µs, sys: 14 µs, total: 31 µs\n",
      "Wall time: 69.9 µs\n",
      "MultiResUnet model loaded\n",
      "7/7 [==============================] - 8s 1s/step\n",
      "0.704641 0.34656984 0.46462098\n",
      "Test Jacard Index : 0.25031778027742135\n",
      "Test Dice Coefficient : 0.369477722758654\n",
      "Test iou_all :0.25220099169174737\n",
      "60/60 [==============================] - 70s 1s/step\n",
      "0.8839493 0.43529186 0.5833292\n",
      "Test Jacard Index : 0.39524455306982526\n",
      "Test Dice Coefficient : 0.5422778033412644\n",
      "Test iou_all :0.40073931490153697\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "%time\n",
    "print('MultiResUnet model loaded')\n",
    "MultiResUnet_model = MultiResUnet(input_filters=32, height=img_height, width=img_width, n_channels=3)\n",
    "MultiResUnet_model.load_weights(\"../models/experiment_2/multiresunet.hdf5\")\n",
    "results_levee = testModel(MultiResUnet_model, X_test, y_test, 4, 'multiresunet_levee')\n",
    "results_deepcrack = testModel(MultiResUnet_model, X_test_DC, y_test_DC, 4, 'multiresunet_deepcrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59571860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 µs, sys: 18 µs, total: 42 µs\n",
      "Wall time: 84.4 µs\n",
      "AttUNet model loaded\n",
      "7/7 [==============================] - 7s 981ms/step\n",
      "0.626786 0.403742 0.49112657\n",
      "Test Jacard Index : 0.280135356013409\n",
      "Test Dice Coefficient : 0.4158171381882567\n",
      "Test iou_all :0.28149163506369024\n",
      "60/60 [==============================] - 53s 892ms/step\n",
      "0.7705007 0.5613572 0.64950794\n",
      "Test Jacard Index : 0.420646290758331\n",
      "Test Dice Coefficient : 0.561999287456679\n",
      "Test iou_all :0.4241672301758641\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "%time\n",
    "print('AttUNet model loaded')\n",
    "AttUNet_model = AttUNet(input_filters=32, height=img_height, width=img_width, n_channels=3)\n",
    "AttUNet_model.load_weights(\"../models/experiment_2/attentionunet.hdf5\")\n",
    "results_levee = testModel(AttUNet_model, X_test, y_test, 4, 'attentionunet_levee')\n",
    "results_deepcrack = testModel(AttUNet_model, X_test_DC, y_test_DC, 4, 'attentionunet_deepcrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6de232a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 64 µs, total: 64 µs\n",
      "Wall time: 138 µs\n",
      "NestedUNet model loaded\n",
      "7/7 [==============================] - 15s 2s/step\n",
      "0.66347206 0.400294 0.49932763\n",
      "Test Jacard Index : 0.2934889376291993\n",
      "Test Dice Coefficient : 0.42778055368610146\n",
      "Test iou_all :0.29654142693317004\n",
      "60/60 [==============================] - 140s 2s/step\n",
      "0.8149447 0.5283849 0.6411002\n",
      "Test Jacard Index : 0.4514945620754344\n",
      "Test Dice Coefficient : 0.5973044892044579\n",
      "Test iou_all :0.4569336542632153\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "%time\n",
    "print(f'NestedUNet model loaded')\n",
    "NestedUNet_model = NestedUNet(input_filters=32, height=img_height, width=img_width, n_channels=3)\n",
    "NestedUNet_model.load_weights(\"../models/experiment_2/nested_unet.hdf5\")\n",
    "results_levee = testModel(NestedUNet_model, X_test, y_test, 4, 'nestedunet_levee')\n",
    "results_deepcrack = testModel(NestedUNet_model, X_test_DC, y_test_DC, 4, 'nestedunet_deepcrack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174e2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "path_test= \"../dataset/experiment_1/test/\"\n",
    "test_images_leveecrack = (next(os.walk(path_test + \"/images\"))[2])\n",
    "\n",
    "image_leveecrack_path = \"../dataset/experiment_1/test/images\"\n",
    "mask_leveecrack_path = \"../dataset/experiment_1/test/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d280cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds_all = []\n",
    "df_all_preds_all = prediction(test_images_leveecrack, os.path.abspath(image_leveecrack_path), os.path.abspath(mask_leveecrack_path), UNet_model, MultiResUnet_model, AttUNet_model, NestedUNet_model, inception_64_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c418f79-05c8-42f5-8b9b-7d044580113e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_visualization = df_all_preds_all.sample(frac = 0.98)\n",
    "show_visualization(df_for_visualization, \"ieee_access_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847ae86-6e91-49da-8d22-1658c887988d",
   "metadata": {},
   "source": [
    "## Inference for DeepCrack Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ef625e-a2f5-4e48-8382-e7dfab3eb684",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "\n",
    "path_test= \"../dataset/experiment_2/deepcrack_test_data/\"\n",
    "test_images_deepcrack = (next(os.walk(path_test + \"/images\"))[2])\n",
    "\n",
    "image_deepcrack_path = \"../dataset/experiment_2/deepcrack_test_data/images\"\n",
    "mask_deepcrack_path = \"../dataset/experiment_2/deepcrack_test_data/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278038b-e1f3-4390-8285-4d604c3653e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_preds_all = []\n",
    "df_all_preds_all = prediction(test_images_deepcrack, os.path.abspath(image_deepcrack_path), os.path.abspath(mask_deepcrack_path), UNet_model, MultiResUnet_model, AttUNet_model, NestedUNet_model, inception_64_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f23c23c-67a1-4a54-9f05-a4dbfd5eaba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_visualization = df_all_preds_all.sample(frac = 0.98)\n",
    "show_visualization(df_for_visualization, \"ieee_access_deepcrack_test_images\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
